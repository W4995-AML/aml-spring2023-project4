{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Homework 4 Spring 2023\n",
        "\n",
        "Due Date - 04/19/2023, 11:59PM\n",
        "\n"
      ],
      "metadata": {
        "id": "7n_4FNWjoc6O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name: <br>\n",
        "UNI: <br>"
      ],
      "metadata": {
        "id": "W3f6uUjpofBh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PART-1: Neural Network from the scratch"
      ],
      "metadata": {
        "id": "j8g3PENtou-K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this part, you are not allowed to use any library other than numpy.\n",
        "\n",
        "In this part, you will will implement the forward pass and backward pass (i.e. the derivates of each parameter wrt to the loss) with the network image uploaded\n",
        "\n",
        "The weight matrix for the hidden layer is W1 and has bias b1.\n",
        "\n",
        "The weight matrix for the ouput layer is W2 and has bias b2.\n",
        "\n",
        "Activatation function is sigmoid for both hidden and output layer\n",
        "\n",
        "Loss function is the MSE loss\n",
        "\n",
        "Refer to the below dictionary for dimensions for each matrix"
      ],
      "metadata": {
        "id": "wL9pCCP9pOXs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JixPBKd2nsfu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pprint \n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0) # don't change this\n",
        "\n",
        "weights = {\n",
        "    'W1': np.random.randn(3, 2),\n",
        "    'b1': np.zeros(3),\n",
        "    'W2': np.random.randn(3),\n",
        "    'b2': 0,\n",
        "}\n",
        "X = np.random.rand(1000,2)\n",
        "Y = np.random.randint(low=0, high=2, size=(1000,))"
      ],
      "metadata": {
        "id": "DSTKLpmmpGWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sigmoid Function\n",
        "def sigmoid(z):\n",
        "    return 1/(1 + np.exp(-z))"
      ],
      "metadata": {
        "id": "ilqdsGibpUo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Implement the forward pass\n",
        "def forward_propagation(X, weights):\n",
        "    # Z1 -> output of the hidden layer before applying activation\n",
        "    # H -> output of the  hidden layer after applying activation\n",
        "    # Z2 -> output of the final layer before applying activation\n",
        "    # Y -> output of the final layer after applying activation\n",
        "    \n",
        "    Z1 = np.dot(X, weights['W1'].T)  + weights['b1']\n",
        "    H = sigmoid(Z1)\n",
        "    \n",
        "    # Z2 = \n",
        "    # Y =\n",
        "\n",
        "    return Y, Z2, H, Z1"
      ],
      "metadata": {
        "id": "jaRxvERRp7Qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement the backward pass\n",
        "# Y_T are the ground truth labels\n",
        "def back_propagation(X, Y_T, weights):\n",
        "    N_points = X.shape[0]\n",
        "    \n",
        "    # forward propagation\n",
        "    Y, Z2, H, Z1 = forward_propagation(X, weights)\n",
        "    L = (1/(2*N_points)) * np.sum(np.square(Y - Y_T))\n",
        "    \n",
        "    # back propagation\n",
        "    dLdY = 1/N_points * (Y - Y_T)\n",
        "    dLdZ2 = np.multiply(dLdY, (sigmoid(Z2)*(1-sigmoid(Z2))))\n",
        "    dLdW2 = np.dot(H.T, dLdZ2)\n",
        "    \n",
        "    # dLdb2 = \n",
        "    # dLdW1 = \n",
        "    # dLdb1 = \n",
        "    \n",
        "    gradients = {\n",
        "        'W1': dLdW1,\n",
        "        'b1': dLdb1,\n",
        "        'W2': dLdW2,\n",
        "        'b2': dLdb2,\n",
        "    }\n",
        "    \n",
        "    return gradients, L"
      ],
      "metadata": {
        "id": "WY2CNasLqGp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradients, L = back_propagation(X, Y, weights)\n",
        "print(L)"
      ],
      "metadata": {
        "id": "hA52qMguqJ_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pp.pprint(gradients)"
      ],
      "metadata": {
        "id": "pzt5G4YdqLEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your answers should be close to L = 0.133 and 'b1': array([ 0.00492, -0.000581, -0.00066])"
      ],
      "metadata": {
        "id": "hi54Q5bLTyqT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PART 2 MNIST Dataset"
      ],
      "metadata": {
        "id": "vqgbkEi44J8k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Description: The MNIST dataset is a widely-used benchmark dataset in the field of machine learning and computer vision. It consists of 70,000 grayscale images of handwritten digits (0-9), with 60,000 images in the training set and 10,000 images in the test set. The images are 28x28 pixels in size, and each pixel is represented by an integer value between 0 and 255, with 0 representing a white pixel and 255 representing a black pixel."
      ],
      "metadata": {
        "id": "FVW4EYXY4Ph3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# The MNIST dataset and the labels have been provided for you\n",
        "(x_dev, y_dev), (x_test, y_test) = mnist.load_data()\n"
      ],
      "metadata": {
        "id": "sb0dpqLi4LV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LABELS = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
      ],
      "metadata": {
        "id": "ESBh6d814bAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.1 Plot 5 samples from each class/label from train set on a 10*5 subplot"
      ],
      "metadata": {
        "id": "eaOh6sOUw2Pc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A07YCUF14xys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2  Preparing the dataset\n",
        "\n",
        "\n",
        "1) Print the shapes - $x_{dev}, y_{dev},x_{test},y_{test}$\n",
        "\n",
        "2) Flatten the images into one-dimensional vectors and again print the shapes of $x_{dev}$,$x_{test}$\n",
        "\n",
        "3) Standardize the development and test sets.\n",
        "\n",
        "4) Train-test split your development set into train and validation sets (8:2 ratio)."
      ],
      "metadata": {
        "id": "A5p0eS9Xw7sj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "30KtGHpC4yxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.3 Build the feed forward network \n",
        "\n",
        "First hidden layer size - 128\n",
        "\n",
        "Second hidden layer size - 64\n",
        "\n",
        "Third and last layer size - You should know this\n"
      ],
      "metadata": {
        "id": "E8bzR2gfxETm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BtcRMdPk5NjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.3.1) Comment briefly on importance of activation functions used."
      ],
      "metadata": {
        "id": "r_EXFCrW2uDS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3M9B6bXb5PML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.4) Print out the model summary"
      ],
      "metadata": {
        "id": "BXk1IWAQxQgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Px4rjLLI5URm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.5) Do you think this number is dependent on the image height and width? "
      ],
      "metadata": {
        "id": "qZl9b9RlxhDp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xbuik7BT5Yty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.6) Use the right metric and  the right loss function and batch size, with Adam as the optimizer, train your model for 10 epochs ."
      ],
      "metadata": {
        "id": "gUzdii-wx17V"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h_ftN-8J6Mfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.7) Plot a separate plots for:\n",
        "\n",
        "a. displaying train vs validation loss over each epoch\n",
        "\n",
        "b. displaying train vs validation accuracy over each epoch "
      ],
      "metadata": {
        "id": "JhUInyXZyKXV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0sU1c3Kg6NOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.8) Finally, report the metric chosen on test set"
      ],
      "metadata": {
        "id": "8FpycdD2ygc_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IebhY_9V6h_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.9 Plot the first 50 samples of test dataset on a 10*5 subplot and this time label the images with both the ground truth (GT) and predicted class (P)."
      ],
      "metadata": {
        "id": "U-2TXjN5zrxi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WxMkTQdV6nIA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}